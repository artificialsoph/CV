<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Computer Vision - GapML CV</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Computer Vision";
    var mkdocs_page_input_path = "tutorials/computer_vision_advanced.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-124527631-2', 'https://gapml.github.io/CV/');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> GapML CV</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">GapML CV</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
    
    <li>Computer Vision</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/gapml/CV/edit/master/docs/tutorials/computer_vision_advanced.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="computer-vision">Computer Vision</h1>
<h2 id="advanced-topics">ADVANCED TOPICS</h2>
<p>This section discusses more advanced topics in uses the <strong>Gap</strong> computer vision module.</p>
<h3 id="processing-errors">Processing Errors</h3>
<p>The <code>Images</code> class tracks images that fail to be preprocessed. Examples for failure are: image does not exist, not an image, etc. The property <code>fail</code> will return the number of images that failed to preprocess and the property <code>errors</code> will return a list of tuples, where each tuple is the corresponding image argument that failed to preprocess, and the reason it failed.</p>
<pre><code class="python"># assume that nonexist.jpg does not exist
images = Images(['good_image.jpg', 'nonexist.jpg'], 1)

# The length of the collection will be only one image (i.e., output from print is 1)
print(len(images))

# Will output 1 for the one failed image (i.e., nonexist.jpg)
print(images.fail)

# Will output: [ ('nonexist.jpg', 'FileNotFoundError') ]
print(images.errors)
</code></pre>

<h3 id="image-dataset-as-numpy-multi-dimensional-array">Image Dataset as Numpy Multi-Dimensional Array</h3>
<p>Many of the machine learning frameworks come with prepared training sets for their tutorials, such as the MNIST, CIFAR, IRIS, etc. In some cases, the training set may already be in a numpy multi-dimensional format:</p>
<p><em>Color RGB</em><br />
  Dimension 1: Number of Images<br />
  Dimension 2: Image Height<br />
  Dimension 3: Image Width<br />
  Dimension 4: Number of Channels  </p>
<p><em>Grayscale</em><br />
  Dimension 1: Number of Images<br />
  Dimension 2: Image Height<br />
  Dimension 3: Image Width  </p>
<p><em>Flatten</em><br />
  Dimension 1: Number of Images<br />
  Dimension 2: Flatten Pixel Data  </p>
<p>This format of a training set can be passed into the Images class as the <code>images</code> parameter. If the data type of the pixel data is <code>uint8</code> or <code>uint16</code>, the pixel data will be normalized; otherwise, data type is float, the pixel data is assumed to be already normalized.</p>
<pre><code class="python"># Let's assume that the image data is already available in memory, such as being read in from file by openCV
import cv2
raw = []
raw.append(cv2.imread('image1.jpg'))  # assume shape is (100, 100, 3)
raw.append(cv2.imread('image2.jpg'))  # assume shape is (100, 100, 3)

# Let's assume now that the list of raw pixel images has been converted to a multi-dimensional numpy array
import numpy as np
dataset = np.asarray(raw)

print(dataset.shape)  # would print: (2, 100, 100, 3)

images = Images(dataset, labels)
print(len(images))      # will output 2
print(images[0].shape)  # will output (100, 100, 3)
</code></pre>

<h3 id="image-dataset-as-image-folder">Image Dataset as Image Folder</h3>
<p>In another case, a dataset is laid out as a set of subdirectories, each containing images, and where each subdirectory is a separate class. This directory/file layout is sometimes referred to as an Image Folder (e.g., Pytorch vision). Below is an example, where the classes are cat and dog:</p>
<pre><code>dataset\
        cat\
            image1.jpg
            image2.jpg
            ...
        dog\
            image3.jpg
            image4.jpg
            ...
</code></pre>

<p>In this case, the root of the dataset (i.e., parent folder, e.g., dataset) is passed as the <code>images</code> parameter and the parameter <code>labels</code> is ignored. Each subdirectory (e.g., cat and dog) is a separate class name. In the above example, all the images under the subdirectories <em>cat</em> and <em>dog</em> are classified as a cat and dog, respectively. The <code>Images</code> object maps the class names (i.e., subdirectories) into integer labels, starting at zero. In the above example, cat <em>cat</em> is assigned the label 0 and <em>dog</em> is assigned the label 1.</p>
<pre><code class="python">cats_and_dogs = Images('dataset', None)
print(cats_and_dogs[0].name, cats_and_dogs[0].label)
# Will output 'image1' and 0
</code></pre>

<p>The mapping of class names to integer labels is obtained from the property <code>classes</code> as a list of tuples, where each tuple is the class name, followed by the corresponding integer label.</p>
<pre><code class="python">print(cats_and_dogs.classes)
# Will output: { 'cat': 0, 'dog', 1 }
</code></pre>

<h3 id="reducing-storage-by-deferring-normalization">Reducing Storage by Deferring Normalization</h3>
<p>In some cases, you may want to reduce your overall storage of the machine learning ready data. By default, each normalized pixel is stored as a float32, which consists of 4 bytes of storage. If the <code>config</code> setting <code>uint8</code> is specified, then normalization of the image is deferred. Instead, each pixel is kept unchanged (non-normalized) and stored as a uint8, which consists of a single byte of storage. For example, if a dataset of 200,000 images of shape (100,100,3) which has been normalized will require 24GB of storage. If stored unnormalized, the data will only require 1/4 the space, or 6GB of storage.</p>
<p>When the dataset is subsequently feed (i.e., properties <code>split</code>, <code>next()</code> and <code>minibatch</code>), the pixel data per image will be normalized in-place each time the image is feed.</p>
<pre><code class="python"># Create the machine learning ready data without normalizing the image data
images = Images(dataset, labels, config=['uint8'])

# set 20% of the dataset as test and 80% as training
images.split = 0.2

# Run 100 epochs of the entire training set through the model
epochs = 100
for _ in range(epochs):
  # get the next image - which will be normalized in-place
  x, y = next(images)

  # send image through the neural network ....
</code></pre>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/gapml/CV/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
